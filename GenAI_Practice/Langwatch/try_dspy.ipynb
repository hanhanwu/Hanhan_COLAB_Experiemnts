{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanhanwu/Hanhan_COLAB_Experiemnts/blob/master/GenAI_Practice/Langwatch/try_dspy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtMIgQScxn3z"
      },
      "source": [
        "# Try DsPy for RAG Prompt Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bv95l62uxm4-"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install --upgrade nbformat\n",
        "%pip install -U --quiet dspy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTn0H1e35Gn9"
      },
      "source": [
        "## Prepare LLM\n",
        "\n",
        "* `http://20.102.90.50:2017/wiki17_abstracts` provides the sources for retrieval here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt49L6d9yCBt",
        "outputId": "3be17457-532c-45dc-bf3c-448d37b6ca0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM test response: ['Silicon Valley is located in the southern part of the San Francisco Bay Area in Northern California, United States. It primarily encompasses parts of Santa Clara County, San Mateo County, and Alameda County, including cities such as San Jose, Palo Alto, Mountain View, Sunnyvale, and Cupertino. Silicon Valley is renowned as a global center for technology innovation, startups, and venture capital.']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import contextlib\n",
        "import pandas as pd\n",
        "from getpass import getpass\n",
        "import dspy\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from dspy.datasets import HotPotQA\n",
        "from dspy.teleprompt import MIPROv2\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "llm = dspy.LM(\"openai/gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
        "\n",
        "# GOOGLE_AI_API_KEY = userdata.get('GOOGLE_AI_API_KEY')\n",
        "# llm = dspy.LM(\"gemini/gemini-2.0-flash\", api_key=GOOGLE_AI_API_KEY)\n",
        "\n",
        "print(\"LLM test response:\", llm(\"Where's Silicon Valley?\"))\n",
        "\n",
        "# the retrieval model\n",
        "colbertv2_wiki17_abstracts = dspy.ColBERTv2(\n",
        "    url=\"http://20.102.90.50:2017/wiki17_abstracts\"\n",
        ")\n",
        "dspy.settings.configure(lm=llm, rm=colbertv2_wiki17_abstracts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZh_Oz8RRRFD"
      },
      "source": [
        "## Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478,
          "referenced_widgets": [
            "f155237bbbe74b4db63d71a0eb436250",
            "350fd92d948c4ac58f4b4cb403ea2b41",
            "cfd936a734ba497ba8fa974067cd1a0d",
            "38ff4578a4ef4e3092e2e29e65854e25",
            "a34457481e28435b9d2cfd970f7ab91e",
            "76fd01bd0e544461ba95fd1829e05f68",
            "e847dfa32b584c1295106b3f99209572",
            "233c2ba7ade3472c92d8141f4784c13e",
            "352cd7a5051e4933b0c09f0a39d6f694",
            "44f8fffdee1c419dbd9ac0c92859b2e8",
            "88d389b449cd4205b65ac91c22b62964",
            "37867882db0f4f2b840f4e355e14562c",
            "23e27b9d6bda4758bc95ea43a70a7dba",
            "43ca1e658f284a76b135d622cc457f8e",
            "03f1aa6bc09c4fc086a09a6fd237eaf3",
            "526cae2337284b86afdd68f21c3599a8",
            "aa1c75acbb9b45c2aab1812d7694b534",
            "dd44a66ce85d4c518053d5e86a905b4a",
            "43a36fd5419f4358abc6d1a2764673c4",
            "745185b7c8e64c489295d7bc3bab8722",
            "8dd5b7c75a4445f38167a6f69f0d7cff",
            "e75eea6322b546a8925c57a4f92eabe2",
            "ff8f27843a8f4ea79a7406410cd71982",
            "f40aacc9af514f30a8ac3215177df4f6",
            "985a588eb66e469a82520f29c44b1067",
            "a928778ddb274e22b67cef45d6a78b0e",
            "4db9257c2dd144608e9cf07a84ff82a0",
            "e85847ee0aab41148e953f9a08529ef9",
            "9d45380758a94f07a2df8fca0a17e1ac",
            "a0fe3959e40848b5bd28a9156b6442ab",
            "ce206665b97443cab0a87248ac069372",
            "7ccfb3a9e43044b89535126b5252407d",
            "cf88ee3b85024171ac53c485262a26c5",
            "1b1df39dc0914cc591454b447085de95",
            "04356fca25f74f1ab6fea2d80a2c62e8",
            "5864962718f44ff1bc2bbd3e19374fa4",
            "54b7a1d354da4f479a1c03ff033868e2",
            "20c2ba1608fc48c197896116106759dd",
            "0546444d119d4e448656c516e7d9ebc7",
            "e628e99e58194234801215e5c6cf332c",
            "ced9e1e7bd704875a84cd636fe233a44",
            "d6e4ce6fc3ff4df9b6b8b7879df58d00",
            "29b62024c0974067a44cbbdae9a48175",
            "e49caba5bb0c4ffa8ad5db37ed6d23d7",
            "61590c2274b640109659e81c26b83cc8",
            "c4ddf7ad3a404c8ca6fa2fdcfb935cd8",
            "2ede969d974e4540b068454d56c7388d",
            "9a29830ea9374abe91f3c3b942fac697",
            "fbc80484e69f4a06921422dfd9c4eeb1",
            "159766f4bea241e28477d60cd87e4004",
            "dda4f068271643fd8122bbe6ae41f941",
            "6ad7d81fe45e4db39e860136537fd7d6",
            "99c7fc55473a4a9398fd630824f09ddc",
            "0b89b5fa36694abdb2e7ccaa8f97c52e",
            "6b25c5adff614d32b4b7d12e1502205b",
            "97f6c6fe9db24e4e8e6e2d26183a8ccd",
            "90f9d8b31fc24d5cb32a1ad9547d1e8d",
            "4a3eefdcce1145fcace297dee0e49c29",
            "77650d5ccf2141c3a4b0a705be84411e",
            "3c7956ba92ed45eebc3da881731754ba",
            "fc61c9fff1664f8293c82896cd21f24e",
            "949f21b678fc47aba944c7bfad8cec5f",
            "de76038901fd46f2b6b3d9c2e87ea42f",
            "8bfe29d0b85c446689d1789e386608aa",
            "e3d14a54381d4cc49daab393096a46d9",
            "1f61bdded6ec46f9a60f21b223c9d6ec",
            "235d430fd34346159bc69ebbdba62b7a",
            "95a8f8ed391d4798b1382847b3177ac9",
            "91e8856fbb66493b92a5b16ec0a8852f",
            "1926e86c89394cfb9622fbb251723e5e",
            "880afc58e0c44661885e5c0880c93a30",
            "d6079869ce774bb9a38ced4be34aa818",
            "bd896fe03c1c430eaf6a28bcdbe9d53f",
            "122e0b9af6cc4c88b9030d11d482f0bc",
            "62529f1c732f451286fe2d9cf44ec9cc",
            "5d8df0bbc8ac48588f8c9ff409fb4177",
            "3d6656f49bb743de81a6ddefc2a28420",
            "4e49a16cfd144f2d9fb3afac77dd7c80",
            "b79e4e42dcfd44f9b9b829ceb14beed5",
            "f49b16e9e3074a178a9e47cafb88c027",
            "6db47248581e48fb9395ba0c94fe283d",
            "b03c0be9f55941f3ae5b8ef9089da709",
            "e55b220845744705805964b2e8dd3a6f",
            "f3a25be0746b4e3a95457032bab72df0",
            "24db49feda5341c38da575f6d24634bb",
            "87c980828b9748638771a65960474470",
            "c47991502c9346f4a8d167318a6b76c8",
            "ac8541e69a25443086a88168b0d0c005"
          ]
        },
        "id": "EREveLxr5FJN",
        "outputId": "a4b54441-ccd9-4f9b-d961-c0b1a76d3701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/9.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f155237bbbe74b4db63d71a0eb436250"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "hotpot_qa.py:   0%|          | 0.00/6.42k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37867882db0f4f2b840f4e355e14562c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/566M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff8f27843a8f4ea79a7406410cd71982"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b1df39dc0914cc591454b447085de95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/46.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61590c2274b640109659e81c26b83cc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/90447 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f6c6fe9db24e4e8e6e2d26183a8ccd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "235d430fd34346159bc69ebbdba62b7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e49a16cfd144f2d9fb3afac77dd7c80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "32 50\n",
            "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})\n",
            "Example({'question': 'Pehchaan: The Face of Truth stars Vinod Khanna, Rati Agnihotri and which Indian actress, producer, and former model who also produced the film?', 'answer': 'Raveena Tandon', 'gold_titles': {'Pehchaan: The Face of Truth', 'Raveena Tandon'}}) (input_keys={'question'})\n"
          ]
        }
      ],
      "source": [
        "dataset = HotPotQA(train_seed=1, train_size=32, eval_seed=2025, dev_size=50, test_size=0)\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]\n",
        "\n",
        "print()\n",
        "print(len(trainset), len(devset))\n",
        "print(trainset[0])\n",
        "print(devset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDMFnJv4R4Ez"
      },
      "source": [
        "## Defining DsPy RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtwHn_RuRVaF",
        "outputId": "dfb60296-3dca-4995-93fa-83a16a20783f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Devset] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
            "[Devset] Answer: Frankie Goes to Hollywood\n",
            "[Devset] Relevant Wikipedia Titles: {'Twelve Inches', 'Frankie Goes to Hollywood'}\n",
            "\n",
            "[Prediction] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
            "[Prediction] Predicted Answer: Bananarama\n",
            "[Prediction] Reasoning: The context mentions three compilation albums with \"Twelve Inch\" in their titles. The first is by Soft Cell, a British band active in the 1980s. The second is by Bananarama, also a British group from the 1980s. The third is by Spandau Ballet, another British band from the 1980s. The question asks specifically about \"Twelve Inches,\" which is most closely associated with Bananarama, as their album is titled \"The Twelve Inches of Bananarama.\" Since the question asks for the band associated with \"Twelve Inches\" and the context explicitly mentions Bananarama's album, the answer is Bananarama.\n"
          ]
        }
      ],
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
        "\n",
        "\n",
        "class RAG(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = self.retrieve(question).passages\n",
        "        prediction = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context,\n",
        "                               answer=prediction.answer,\n",
        "                               reasoning=prediction.reasoning)\n",
        "\n",
        "\n",
        "dev_example = devset[12]\n",
        "print(f\"[Devset] Question: {dev_example.question}\")\n",
        "print(f\"[Devset] Answer: {dev_example.answer}\")\n",
        "print(f\"[Devset] Relevant Wikipedia Titles: {dev_example.gold_titles}\")\n",
        "print()\n",
        "\n",
        "generate_answer = RAG()\n",
        "pred = generate_answer(question=dev_example.question)\n",
        "print(f\"[Prediction] Question: {dev_example.question}\")\n",
        "print(f\"[Prediction] Predicted Answer: {pred.answer}\")\n",
        "print(f\"[Prediction] Reasoning: {pred.reasoning}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "zomfBJNbFy0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5acfd4-b7f1-4352-ba38-329d06185542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/05 03:14:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/06/05 03:14:18 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/06/05 03:14:18 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=2 sets of demonstrations...\n",
            "2025/06/05 03:14:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/06/05 03:14:18 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
            "2025/06/05 03:14:21 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing N=2 instructions...\n",
            "\n",
            "2025/06/05 03:14:28 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/06/05 03:14:28 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Answer questions with short factoid answers.\n",
            "\n",
            "2025/06/05 03:14:28 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Generate a clear and concise instruction instructing a language model to answer fact-based questions accurately by retrieving relevant context and reasoning through the information step-by-step to produce a short, factual answer, typically between 1 and 5 words. Emphasize clarity and brevity to ensure precise responses.\n",
            "\n",
            "2025/06/05 03:14:28 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/06/05 03:14:28 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/06/05 03:14:28 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2025/06/05 03:14:28 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 7 - Full Evaluation of Default Program ==\n",
            "2025/06/05 03:14:34 INFO dspy.evaluate.evaluate: Average Metric: 9 / 25 (36.0%)\n",
            "2025/06/05 03:14:34 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 36.0\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "2025/06/05 03:14:34 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 7 - Minibatch ==\n",
            "2025/06/05 03:14:36 INFO dspy.evaluate.evaluate: Average Metric: 3 / 4 (75.0%)\n",
            "2025/06/05 03:14:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/06/05 03:14:36 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [75.0]\n",
            "2025/06/05 03:14:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/05 03:14:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/05 03:14:36 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/05 03:14:36 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 7 - Minibatch ==\n",
            "2025/06/05 03:14:37 INFO dspy.evaluate.evaluate: Average Metric: 1 / 4 (25.0%)\n",
            "2025/06/05 03:14:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/06/05 03:14:37 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [75.0, 25.0]\n",
            "2025/06/05 03:14:37 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/05 03:14:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/05 03:14:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/05 03:14:37 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 7 - Minibatch ==\n",
            "2025/06/05 03:14:39 INFO dspy.evaluate.evaluate: Average Metric: 0 / 4 (0.0%)\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [75.0, 25.0, 0.0]\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 7 - Minibatch ==\n",
            "2025/06/05 03:14:39 INFO dspy.evaluate.evaluate: Average Metric: 1 / 4 (25.0%)\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [75.0, 25.0, 0.0, 25.0]\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/05 03:14:39 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 7 - Minibatch ==\n",
            "2025/06/05 03:14:40 INFO dspy.evaluate.evaluate: Average Metric: 3 / 4 (75.0%)\n",
            "2025/06/05 03:14:40 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/06/05 03:14:40 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [75.0, 25.0, 0.0, 25.0, 75.0]\n",
            "2025/06/05 03:14:40 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/05 03:14:40 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/05 03:14:40 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/05 03:14:40 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 7 - Full Evaluation =====\n",
            "2025/06/05 03:14:40 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 75.0) from minibatch trials...\n",
            "2025/06/05 03:14:49 INFO dspy.evaluate.evaluate: Average Metric: 12 / 25 (48.0%)\n",
            "2025/06/05 03:14:49 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 48.0\n",
            "2025/06/05 03:14:49 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0, 48.0]\n",
            "2025/06/05 03:14:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 48.0\n",
            "2025/06/05 03:14:49 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/06/05 03:14:49 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/06/05 03:14:49 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 48.0!\n"
          ]
        }
      ],
      "source": [
        "def validate_context_and_answer(example, prediction):\n",
        "    gold = example.answer.strip().lower()\n",
        "    pred = prediction.answer.strip().lower()\n",
        "    score = int(gold == pred)\n",
        "\n",
        "    print(f\"[Trial] Q: {example.question} | Pred: {pred} | GT: {gold} | Score: {score}\")\n",
        "    return score\n",
        "\n",
        "\n",
        "optimizer = MIPROv2(\n",
        "    metric=validate_context_and_answer,\n",
        "    prompt_model=llm,\n",
        "    task_model=llm,\n",
        "    num_candidates=2,  # number of proposed instructions\n",
        "    init_temperature=0.7,\n",
        "    auto=None\n",
        ")\n",
        "\n",
        "\n",
        "with open('dspy_compile_output.txt', 'w') as f:\n",
        "    with contextlib.redirect_stdout(f):\n",
        "        compiled_rag = optimizer.compile(\n",
        "            RAG(),\n",
        "            trainset=trainset,\n",
        "            num_trials=5,\n",
        "            max_bootstrapped_demos=2,\n",
        "            max_labeled_demos=3,\n",
        "            minibatch_size=4,\n",
        "            requires_permission_to_run=False\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-eJQmhJMMax",
        "outputId": "80205e34-8f1b-4c1d-ea34-63fb757503cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_answer.predict = Predict(StringSignature(context, question -> reasoning, answer\n",
              "    instructions='Answer questions with short factoid answers.'\n",
              "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
              "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
              "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
              "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
              "))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# optimized results\n",
        "compiled_rag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SvWBVf9bFzZf",
        "outputId": "7d2b4a7e-93fa-4944-e395-699a2703449f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test on dev example ---\n",
            "Question: Pehchaan: The Face of Truth stars Vinod Khanna, Rati Agnihotri and which Indian actress, producer, and former model who also produced the film?\n",
            "Predicted Answer: Raveena Tandon\n",
            "Ground Truth: Raveena Tandon\n"
          ]
        }
      ],
      "source": [
        "# example output with optimized results\n",
        "dev_example = devset[0]\n",
        "pred = compiled_rag(question=dev_example.question)\n",
        "print(\"\\n--- Test on dev example ---\")\n",
        "print(f\"Question: {dev_example.question}\")\n",
        "print(f\"Predicted Answer: {pred.answer}\")\n",
        "print(f\"Ground Truth: {dev_example.answer}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
