{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanhanwu/Hanhan_COLAB_Experiemnts/blob/master/GenAI_Practice/Langwatch/try_dspy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtMIgQScxn3z"
      },
      "source": [
        "# Try DsPy for RAG Prompt Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bv95l62uxm4-"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install --upgrade nbformat\n",
        "%pip install -U --quiet dspy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTn0H1e35Gn9"
      },
      "source": [
        "## Prepare LLM\n",
        "\n",
        "* `http://20.102.90.50:2017/wiki17_abstracts` provides the sources for retrieval here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt49L6d9yCBt",
        "outputId": "e8e981f4-03df-46b9-c2b2-b2b2710a5246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM test response: ['Silicon Valley is located in the southern part of the San Francisco Bay Area in Northern California, United States. It primarily encompasses parts of Santa Clara County, San Mateo County, and Alameda County. The region is renowned as a global center for technology, innovation, and venture capital, home to many major tech companies and startups.']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import contextlib\n",
        "import pandas as pd\n",
        "from getpass import getpass\n",
        "import dspy\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from dspy.datasets import HotPotQA\n",
        "from dspy.teleprompt import MIPROv2\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "llm = dspy.LM(\"openai/gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
        "\n",
        "# GOOGLE_AI_API_KEY = userdata.get('GOOGLE_AI_API_KEY')\n",
        "# llm = dspy.LM(\"gemini/gemini-2.0-flash\", api_key=GOOGLE_AI_API_KEY)\n",
        "\n",
        "print(\"LLM test response:\", llm(\"Where's Silicon Valley?\"))\n",
        "\n",
        "# the retrieval model\n",
        "colbertv2_wiki17_abstracts = dspy.ColBERTv2(\n",
        "    url=\"http://20.102.90.50:2017/wiki17_abstracts\"\n",
        ")\n",
        "dspy.settings.configure(lm=llm, rm=colbertv2_wiki17_abstracts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZh_Oz8RRRFD"
      },
      "source": [
        "## Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478,
          "referenced_widgets": [
            "b0567ce655114ba180128da8f093421e",
            "4528aaad36a34b60b6b1c1c5218677dc",
            "f5fdee244d584f2b9a8f0a82a2748abb",
            "9e430ffb4fa4474bb0a7dd3753e261d1",
            "2b6304de93dd4ff8ac22ca47a3555db1",
            "40419276973f4fba965a513d7116f612",
            "6c1d02df512e42e8b1447a6cdbf9abb8",
            "9a44131bdfee49deb905e243fc08994f",
            "48759619dd5e4958a1c9c3aaa03861a5",
            "d1df7fdcab4445c091713f009e10a9b7",
            "4f83322b70c443169703042e2a62af87",
            "2bc145bd49f14163a5658fc746d259d5",
            "7563aac5441b4e3ba32296432a82bf62",
            "eff40004c38f42a680d66e3b7074d41e",
            "d46ba3d225d04b1c8d34ec9f7399bf27",
            "49a03d5714f749d3913f1dd43be00c70",
            "63e00a72d5ec421982b9a0e5e1656cdc",
            "0211fccedba5401dab697a5d66bf627e",
            "1886a8848794480fad450d7265665c2f",
            "45e951b6d9d04e7da3fec5f8d5b57e76",
            "c340b9c3fe3a46168d66b29ede930fda",
            "30ac4850bc2a4faca9070f8b27319560",
            "0ea7a6e31ae14a168722c5ff10399feb",
            "6243e0b0b53e4c3d8bec8eab673fa18a",
            "4b868ba46cc4471da4c9814c4935be31",
            "13e40ddda510468487ea6408b4557403",
            "be82a1ca87db4d838d68af897518ee88",
            "18ca3c8933e1434b9f2b1e9514534128",
            "fc3e27f201954859aa8430ab06d06411",
            "370eb03f847e4633aeb05abdd2de2087",
            "580af67a50594050bafac20791b3a20c",
            "54045b471a0045d4981adb590413904f",
            "7724d0ed130d4506b60a91b797ab9b47",
            "6d039d0ef55849deaaa2f3b6fd42987b",
            "14172ffbe03c48aca815987eadf525e2",
            "963cdce23f5448c5aed73f0853139c5b",
            "42aed198ac4548c680072e2d1885d66f",
            "e95628347ef14dc9a709df759af5e35d",
            "f6d6d763379a43939edf2e47872279d5",
            "3f8e73ff22684cc181c4230be9c37e57",
            "3d31ce4bc64a4940ac0bdbe07662ec37",
            "3066d558065a42db86812bff54f3c67e",
            "a459cc4b156b4fe2a6ed7c0bfb1608b4",
            "40a8a99817d049c3a070303130f53629",
            "87a05fcfe15e43098ba47d9b1451be99",
            "f27469618b324424a7e007ff78ec2472",
            "340da44a6b204dd0bbbd3fb7a8281c4a",
            "9be033b50bec49f8887b741012953e3b",
            "992d66b75987480fb8627e4c88a2da9d",
            "a86ee30a5d3f4deea51a5df652c88546",
            "0774cb9d2b0e4613af2a4f181f516096",
            "88819b1ae4e8437caf23de69981f3a8f",
            "7f4542fa6ca54a7f98cf81b3fee8bce5",
            "d1148921339f41f4a3a35b022e7c4045",
            "2ebd61ac73d644c49bec4b1a578d7bf4",
            "0e6640e06a674b6fa696e107f7f39f84",
            "b78cdadb4f774cb194161618af0ab21a",
            "f9643704a1ac48dcad29be1293bbe4c2",
            "d6970d47890f40eda028d115ed35718a",
            "0be5a2b215df4499b327bd65fed11d45",
            "d726194185fe4229a2fae3b7fb031062",
            "063fa27d6e1344f68b96dd11fd482d5f",
            "081a40211c094e63b831e2df22d22906",
            "602060bd81704597a98c0ca9884d68e4",
            "55aa47a34461468d96a24243c9245e91",
            "d69adfe75b834d05b00ebac6cfc91082",
            "a2706f40c00540918e99fc0cbc3a85a3",
            "67ab4299c951466782dac7585db56ef4",
            "ea023eb3eeab47dab6a11953d44efaea",
            "63a3fd2324ba4965b5a1823f7f88b269",
            "7edd44ff4c0e4601937d95f6e16b6598",
            "0a22f0726d4d46b5837844563dc936fb",
            "822f384c5ba0408a9e1123821fd6d311",
            "5d8eee880385494883a923429c70b269",
            "96358e4aa3cf41c88023b53dd943089f",
            "9dad2c015dfc48eab8f48a98028ba396",
            "a80fa29173954144b9136262944ea0c8",
            "6ecdf387a05c44a5ba97830e6614bd18",
            "eef1657fa3d94786aca99d51f0d0e58e",
            "592dbb5fcfbd4434966030c69072f6c2",
            "3c779c6c7c1544aa8d55d871da160d65",
            "5dd0af46e0764c84a915a103c36d5c17",
            "fdf56fd207864256a25d3a2e193171e7",
            "4354da3120e14e88aaa50561c8b9944c",
            "25f6ab954d104d628516debfbfe6dbab",
            "1496f2f6e496493999957ac547aec1da",
            "1fbbcb9ae825422cb9ebb7c3a163c8d5",
            "59b40aeacd184a2492fb45c5253dec3a"
          ]
        },
        "id": "EREveLxr5FJN",
        "outputId": "a537745b-552d-4926-9572-ee30f113c59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/9.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0567ce655114ba180128da8f093421e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "hotpot_qa.py:   0%|          | 0.00/6.42k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bc145bd49f14163a5658fc746d259d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/566M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ea7a6e31ae14a168722c5ff10399feb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d039d0ef55849deaaa2f3b6fd42987b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/46.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87a05fcfe15e43098ba47d9b1451be99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/90447 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e6640e06a674b6fa696e107f7f39f84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2706f40c00540918e99fc0cbc3a85a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ecdf387a05c44a5ba97830e6614bd18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "32 50\n",
            "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})\n",
            "Example({'question': 'Pehchaan: The Face of Truth stars Vinod Khanna, Rati Agnihotri and which Indian actress, producer, and former model who also produced the film?', 'answer': 'Raveena Tandon', 'gold_titles': {'Raveena Tandon', 'Pehchaan: The Face of Truth'}}) (input_keys={'question'})\n"
          ]
        }
      ],
      "source": [
        "dataset = HotPotQA(train_seed=1, train_size=32, eval_seed=2025, dev_size=50, test_size=0)\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]\n",
        "\n",
        "print()\n",
        "print(len(trainset), len(devset))\n",
        "print(trainset[0])\n",
        "print(devset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDMFnJv4R4Ez"
      },
      "source": [
        "## Defining DsPy RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtwHn_RuRVaF",
        "outputId": "05035594-122e-4738-db06-dbf840c2b288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Devset] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
            "[Devset] Answer: Frankie Goes to Hollywood\n",
            "[Devset] Relevant Wikipedia Titles: {'Twelve Inches', 'Frankie Goes to Hollywood'}\n",
            "\n",
            "[Prediction] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
            "[Prediction] Predicted Answer: Bananarama\n",
            "[Prediction] Reasoning: The context mentions three compilation albums with \"Twelve Inch\" in their titles. The first is by Soft Cell, a British band active in the 1980s. The second is by Bananarama, also a British group from the 1980s. The third is by Spandau Ballet, another British band from the 1980s. The question asks specifically about \"Twelve Inches,\" which is the album by Bananarama, a British band from the 1980s.\n"
          ]
        }
      ],
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
        "\n",
        "\n",
        "class RAG(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = self.retrieve(question).passages\n",
        "        prediction = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context,\n",
        "                               answer=prediction.answer,\n",
        "                               reasoning=prediction.reasoning)\n",
        "\n",
        "\n",
        "dev_example = devset[12]\n",
        "print(f\"[Devset] Question: {dev_example.question}\")\n",
        "print(f\"[Devset] Answer: {dev_example.answer}\")\n",
        "print(f\"[Devset] Relevant Wikipedia Titles: {dev_example.gold_titles}\")\n",
        "print()\n",
        "\n",
        "generate_answer = RAG()\n",
        "pred = generate_answer(question=dev_example.question)\n",
        "print(f\"[Prediction] Question: {dev_example.question}\")\n",
        "print(f\"[Prediction] Predicted Answer: {pred.answer}\")\n",
        "print(f\"[Prediction] Reasoning: {pred.reasoning}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "zomfBJNbFy0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e61aac8-f8ad-439c-aa29-de097ed2b47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/06/06 02:40:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/06/06 02:40:33 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/06/06 02:40:33 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=2 sets of demonstrations...\n",
            "2025/06/06 02:40:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/06/06 02:40:33 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
            "2025/06/06 02:40:35 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing N=2 instructions...\n",
            "\n",
            "2025/06/06 02:40:43 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/06/06 02:40:43 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Answer questions with short factoid answers.\n",
            "\n",
            "2025/06/06 02:40:43 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given a set of relevant passages or context related to a factual question, generate a concise, accurate answer that directly responds to the question. Additionally, provide a step-by-step reasoning process explaining how you arrived at the answer, ensuring that your explanation reflects a clear understanding of the facts. Your responses should be brief and focused, emphasizing correctness and clarity to support knowledge verification tasks involving questions about names, dates, and specific details across various subjects. Carefully consider the context, think through the facts logically, and craft an answer that is both precise and supported by the retrieved information.\n",
            "\n",
            "2025/06/06 02:40:43 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/06/06 02:40:43 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/06/06 02:40:43 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2025/06/06 02:40:43 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 7 - Full Evaluation of Default Program ==\n",
            "2025/06/06 02:40:48 INFO dspy.evaluate.evaluate: Average Metric: 9 / 25 (36.0%)\n",
            "2025/06/06 02:40:48 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 36.0\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "2025/06/06 02:40:48 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 7 - Minibatch ==\n",
            "2025/06/06 02:40:48 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
            "\n",
            "2025/06/06 02:40:51 INFO dspy.evaluate.evaluate: Average Metric: 0 / 4 (0.0%)\n",
            "2025/06/06 02:40:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/06/06 02:40:51 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [0.0]\n",
            "2025/06/06 02:40:51 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/06 02:40:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/06 02:40:51 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/06 02:40:51 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 7 - Minibatch ==\n",
            "2025/06/06 02:40:51 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
            "\n",
            "2025/06/06 02:40:52 INFO dspy.evaluate.evaluate: Average Metric: 2 / 4 (50.0%)\n",
            "2025/06/06 02:40:52 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/06/06 02:40:52 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [0.0, 50.0]\n",
            "2025/06/06 02:40:52 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/06 02:40:52 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/06 02:40:52 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/06 02:40:52 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 7 - Minibatch ==\n",
            "2025/06/06 02:40:52 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
            "\n",
            "2025/06/06 02:40:53 INFO dspy.evaluate.evaluate: Average Metric: 1 / 4 (25.0%)\n",
            "2025/06/06 02:40:53 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/06/06 02:40:53 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [0.0, 50.0, 25.0]\n",
            "2025/06/06 02:40:53 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/06 02:40:53 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/06 02:40:53 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/06 02:40:53 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 7 - Minibatch ==\n",
            "2025/06/06 02:40:53 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
            "\n",
            "2025/06/06 02:40:55 INFO dspy.evaluate.evaluate: Average Metric: 2 / 4 (50.0%)\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [0.0, 50.0, 25.0, 50.0]\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 7 - Minibatch ==\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
            "\n",
            "2025/06/06 02:40:55 INFO dspy.evaluate.evaluate: Average Metric: 1 / 4 (25.0%)\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 on minibatch of size 4 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [0.0, 50.0, 25.0, 50.0, 25.0]\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0]\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 36.0\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
            "\n",
            "\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 7 - Full Evaluation =====\n",
            "2025/06/06 02:40:55 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 50.0) from minibatch trials...\n",
            "2025/06/06 02:40:58 INFO dspy.evaluate.evaluate: Average Metric: 12 / 25 (48.0%)\n",
            "2025/06/06 02:40:58 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 48.0\n",
            "2025/06/06 02:40:58 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [36.0, 48.0]\n",
            "2025/06/06 02:40:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 48.0\n",
            "2025/06/06 02:40:58 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/06/06 02:40:58 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/06/06 02:40:58 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 48.0!\n"
          ]
        }
      ],
      "source": [
        "def validate_context_and_answer(example, prediction):\n",
        "    gold = example.answer.strip().lower()\n",
        "    pred = prediction.answer.strip().lower()\n",
        "    score = int(gold == pred)\n",
        "\n",
        "    print(f\"[Trial] Q: {example.question} | Pred: {pred} | GT: {gold} | Score: {score}\")\n",
        "    return score\n",
        "\n",
        "\n",
        "optimizer = MIPROv2(\n",
        "    metric=validate_context_and_answer,\n",
        "    prompt_model=llm,\n",
        "    task_model=llm,\n",
        "    num_candidates=2,  # number of proposed instructions\n",
        "    init_temperature=0.7,\n",
        "    seed=10,\n",
        "    auto=None,\n",
        "    verbose=True,\n",
        "    track_stats=True\n",
        ")\n",
        "\n",
        "\n",
        "with open('dspy_miprov2_verbose_stats.txt', 'w') as f:\n",
        "    with contextlib.redirect_stdout(f):\n",
        "        compiled_rag = optimizer.compile(\n",
        "            RAG(),\n",
        "            trainset=trainset,\n",
        "            num_trials=5,\n",
        "            max_bootstrapped_demos=2,\n",
        "            max_labeled_demos=3,\n",
        "            minibatch_size=4,\n",
        "            requires_permission_to_run=False\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-eJQmhJMMax",
        "outputId": "19185aa3-5958-41a7-c16f-5bbe514fdfd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_answer.predict = Predict(StringSignature(context, question -> reasoning, answer\n",
              "    instructions='Given a set of relevant passages or context related to a factual question, generate a concise, accurate answer that directly responds to the question. Additionally, provide a step-by-step reasoning process explaining how you arrived at the answer, ensuring that your explanation reflects a clear understanding of the facts. Your responses should be brief and focused, emphasizing correctness and clarity to support knowledge verification tasks involving questions about names, dates, and specific details across various subjects. Carefully consider the context, think through the facts logically, and craft an answer that is both precise and supported by the retrieved information.'\n",
              "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
              "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
              "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
              "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
              "))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# optimized results\n",
        "compiled_rag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SvWBVf9bFzZf",
        "outputId": "f75f0395-272d-4b6e-e643-d31809f08ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test on dev example ---\n",
            "Question: Pehchaan: The Face of Truth stars Vinod Khanna, Rati Agnihotri and which Indian actress, producer, and former model who also produced the film?\n",
            "Predicted Answer: Raveena Tandon\n",
            "Ground Truth: Raveena Tandon\n"
          ]
        }
      ],
      "source": [
        "# example output with optimized results\n",
        "dev_example = devset[0]\n",
        "pred = compiled_rag(question=dev_example.question)\n",
        "print(\"\\n--- Test on dev example ---\")\n",
        "print(f\"Question: {dev_example.question}\")\n",
        "print(f\"Predicted Answer: {pred.answer}\")\n",
        "print(f\"Ground Truth: {dev_example.answer}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
