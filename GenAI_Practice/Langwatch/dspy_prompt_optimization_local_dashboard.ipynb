{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffb2388",
   "metadata": {},
   "source": [
    "# DsPy Prompt Optimization with Local Langwatch\n",
    "\n",
    "* Notes\n",
    "  * In order to launch Langwatch locally, in `compse.yaml` file\n",
    "    * Comment out `- \"_JAVA_OPTIONS=-XX:UseSVE=0\"`\n",
    "    * Comment out the resources\n",
    "  * And seems that Langwatch local version doesn't work for gemini flash 2.0...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16094eef",
   "metadata": {},
   "source": [
    "## Preparing the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a758488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wuhan\\OneDrive\\Documents\\GitHub\\Hanhan_COLAB_Experiemnts\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM test response: ['As of my knowledge cutoff in October 2023, Robert Nishihara is a researcher known for his work in the fields of machine learning, reinforcement learning, and distributed systems. He has contributed to the development of frameworks and algorithms that improve the scalability and efficiency of machine learning workflows. Nishihara has been involved with projects such as Ray, an open-source framework for distributed computing, which aims to simplify the development of scalable applications. He has also published research papers on topics related to reinforcement learning, parallel computing, and system design. If you have specific questions about his work or background, feel free to ask!']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "llm = dspy.LM(\"openai/gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
    "print(\"LLM test response:\", llm(\"How much do you know about Robert Nishihara?\"))\n",
    "\n",
    "# the retrieval model\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(\n",
    "    url=\"http://20.102.90.50:2017/wiki17_abstracts\"\n",
    ")\n",
    "dspy.settings.configure(lm=llm, rm=colbertv2_wiki17_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c509fe",
   "metadata": {},
   "source": [
    "## Preparing the Dataset for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ec8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 50\n",
      "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})\n",
      "Example({'question': 'Pehchaan: The Face of Truth stars Vinod Khanna, Rati Agnihotri and which Indian actress, producer, and former model who also produced the film?', 'answer': 'Raveena Tandon', 'gold_titles': {'Pehchaan: The Face of Truth', 'Raveena Tandon'}}) (input_keys={'question'})\n"
     ]
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "\n",
    "dataset = HotPotQA(train_seed=1, train_size=32, eval_seed=2025, dev_size=50, test_size=0)\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "print(len(trainset), len(devset))\n",
    "print(trainset[0])\n",
    "print(devset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48758f",
   "metadata": {},
   "source": [
    "## Define RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437f2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Devset] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
      "[Devset] Answer: Frankie Goes to Hollywood\n",
      "[Devset] Relevant Wikipedia Titles: {'Twelve Inches', 'Frankie Goes to Hollywood'}\n",
      "\n",
      "[Prediction] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
      "[Prediction] Predicted Answer: Spandau Ballet\n"
     ]
    }
   ],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "\n",
    "dev_example = devset[12]\n",
    "print(f\"[Devset] Question: {dev_example.question}\")\n",
    "print(f\"[Devset] Answer: {dev_example.answer}\")\n",
    "print(f\"[Devset] Relevant Wikipedia Titles: {dev_example.gold_titles}\")\n",
    "print()\n",
    "\n",
    "generate_answer = RAG()\n",
    "pred = generate_answer(question=dev_example.question)\n",
    "print(f\"[Prediction] Question: {dev_example.question}\")\n",
    "print(f\"[Prediction] Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a6c604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangWatch API key is already set, if you want to login again, please call as langwatch.login(relogin=True)\n"
     ]
    }
   ],
   "source": [
    "import langwatch\n",
    "\n",
    "\n",
    "langwatch.endpoint = \"http://localhost:5560\"\n",
    "langwatch.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b4f44",
   "metadata": {},
   "source": [
    "## Start Training Session\n",
    "\n",
    "* Notes\n",
    "  * `langwatch.dspy.init()` worked when I was using \"https://app.langwatch.ai\" as endpoint, but when using \"http://localhost:5560\" as the endpoint here, have to use `langwatch.dspy.__init__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__bool__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
     ]
    }
   ],
   "source": [
    "import langwatch\n",
    "print(dir(langwatch.dspy))  # try to find the init() function in langwatch.dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "150ffef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:27:40 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/05/19 16:27:40 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/05/19 16:27:40 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=2 sets of demonstrations...\n",
      "2025/05/19 16:27:40 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/05/19 16:27:40 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/2\n",
      "Bootstrapping set 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:27:45 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n",
      "2025/05/19 16:27:55 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/05/19 16:27:55 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Answer questions with short factoid answers.\n",
      "\n",
      "2025/05/19 16:27:55 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given a context containing relevant facts and a specific question, analyze the information step-by-step to reason through the answer. Provide a concise, factual response that is typically between one and five words. Ensure your answer directly addresses the question using the context provided.\n",
      "\n",
      "2025/05/19 16:27:55 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/05/19 16:27:55 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/05/19 16:27:55 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/05/19 16:27:55 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 12 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 25 (24.0%): 100%|██████████| 25/25 [00:08<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:04 INFO dspy.evaluate.evaluate: Average Metric: 6 / 25 (24.0%)\n",
      "2025/05/19 16:28:04 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 24.0\n",
      "\n",
      "c:\\Users\\wuhan\\OneDrive\\Documents\\GitHub\\Hanhan_COLAB_Experiemnts\\.venv\\Lib\\site-packages\\optuna\\_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/05/19 16:28:04 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.00 / 10 (20.0%): 100%|██████████| 10/10 [00:03<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:08 INFO dspy.evaluate.evaluate: Average Metric: 2 / 10 (20.0%)\n",
      "2025/05/19 16:28:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/05/19 16:28:08 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0]\n",
      "2025/05/19 16:28:08 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:08 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:08 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.00 / 10 (30.0%): 100%|██████████| 10/10 [00:04<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:12 INFO dspy.evaluate.evaluate: Average Metric: 3 / 10 (30.0%)\n",
      "2025/05/19 16:28:12 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 30.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/05/19 16:28:12 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0]\n",
      "2025/05/19 16:28:12 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:12 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:12 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.00 / 10 (30.0%): 100%|██████████| 10/10 [00:04<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:16 INFO dspy.evaluate.evaluate: Average Metric: 3 / 10 (30.0%)\n",
      "2025/05/19 16:28:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 30.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/05/19 16:28:16 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0, 30.0]\n",
      "2025/05/19 16:28:16 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:16 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:16 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.00 / 10 (30.0%): 100%|██████████| 10/10 [00:00<00:00, 271.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:17 INFO dspy.evaluate.evaluate: Average Metric: 3 / 10 (30.0%)\n",
      "2025/05/19 16:28:17 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 30.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/05/19 16:28:17 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0, 30.0, 30.0]\n",
      "2025/05/19 16:28:17 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:17 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:17 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:17 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.00 / 10 (50.0%): 100%|██████████| 10/10 [00:04<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:21 INFO dspy.evaluate.evaluate: Average Metric: 5 / 10 (50.0%)\n",
      "2025/05/19 16:28:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/05/19 16:28:21 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0, 30.0, 30.0, 50.0]\n",
      "2025/05/19 16:28:21 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:21 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:21 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 7 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.00 / 10 (50.0%): 100%|██████████| 10/10 [00:03<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:24 INFO dspy.evaluate.evaluate: Average Metric: 5 / 10 (50.0%)\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0, 30.0, 30.0, 50.0, 50.0]\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.00 / 10 (10.0%): 100%|██████████| 10/10 [00:00<00:00, 189.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:24 INFO dspy.evaluate.evaluate: Average Metric: 1 / 10 (10.0%)\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 10.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 10.0]\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:24 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.00 / 10 (40.0%): 100%|██████████| 10/10 [00:05<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:30 INFO dspy.evaluate.evaluate: Average Metric: 4 / 10 (40.0%)\n",
      "2025/05/19 16:28:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 40.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/05/19 16:28:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 10.0, 40.0]\n",
      "2025/05/19 16:28:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:30 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 12 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.00 / 10 (20.0%): 100%|██████████| 10/10 [00:02<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:33 INFO dspy.evaluate.evaluate: Average Metric: 2 / 10 (20.0%)\n",
      "2025/05/19 16:28:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/05/19 16:28:33 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 10.0, 40.0, 20.0]\n",
      "2025/05/19 16:28:33 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0]\n",
      "2025/05/19 16:28:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 24.0\n",
      "2025/05/19 16:28:33 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/05/19 16:28:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 12 - Full Evaluation =====\n",
      "2025/05/19 16:28:33 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 35.0) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.00 / 25 (32.0%): 100%|██████████| 25/25 [00:02<00:00,  9.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/19 16:28:36 INFO dspy.evaluate.evaluate: Average Metric: 8 / 25 (32.0%)\n",
      "2025/05/19 16:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 32.0\n",
      "2025/05/19 16:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [24.0, 32.0]\n",
      "2025/05/19 16:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 32.0\n",
      "2025/05/19 16:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/05/19 16:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/05/19 16:28:36 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 32.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "import dspy.evaluate\n",
    "\n",
    "\n",
    "# Define our metric validation\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a MIPROv2 optimizer, which will compile our RAG program.\n",
    "optimizer = MIPROv2(metric=validate_context_and_answer, prompt_model=llm,\n",
    "                    task_model=llm, num_candidates=2, init_temperature=0.7,\n",
    "                    auto=None)\n",
    "\n",
    "# Initialize langwatch for this run, to track the optimizer compilation\n",
    "langwatch.dspy.__init__(experiment=\"hanhan_exp1\", optimizer=optimizer)\n",
    "\n",
    "# Compile\n",
    "compiled_rag = optimizer.compile( RAG(),\n",
    "    trainset=trainset,\n",
    "    num_trials=10,\n",
    "    max_bootstrapped_demos=3,\n",
    "    max_labeled_demos=5,\n",
    "    minibatch_size=10,\n",
    "    requires_permission_to_run=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "918afc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_answer.predict = Predict(StringSignature(context, question -> reasoning, answer\n",
       "    instructions='Given a context containing relevant facts and a specific question, analyze the information step-by-step to reason through the answer. Provide a concise, factual response that is typically between one and five words. Ensure your answer directly addresses the question using the context provided.'\n",
       "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
       "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
       "))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_rag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
