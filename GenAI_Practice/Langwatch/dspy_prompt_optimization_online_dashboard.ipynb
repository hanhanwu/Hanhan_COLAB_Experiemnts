{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanhanwu/Hanhan_COLAB_Experiemnts/blob/master/GenAI_Practice/Langwatch/dspy_prompt_optimization_online_dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlUZDfYZyxvF"
      },
      "source": [
        "# LangWatch DSPy Visualizer\n",
        "\n",
        "This notebook shows an example of a simple DSPy optimization process integrated with LangWatch for training visualization and debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pgy1Fjhh_lOB"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install --upgrade nbformat\n",
        "%pip install -U --quiet dspy langwatch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51OWavv1CCVV"
      },
      "source": [
        "## Preparing the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xycw8IWs_qnt",
        "outputId": "455a91cb-3598-4adc-970a-9df8ec04a554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM test response: ['As of my knowledge cutoff in October 2023, Robert Nishihara is a researcher known for his work in machine learning, particularly in the areas of reinforcement learning, optimization, and scalable algorithms. He has contributed to the development of tools and frameworks that facilitate large-scale machine learning experiments. Nishihara has been affiliated with institutions such as the University of California, Berkeley, and has collaborated on projects related to distributed computing and efficient training methods for complex models. If you have specific questions about his work or background, feel free to ask!']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import dspy\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "llm = dspy.LM(\"openai/gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
        "print(\"LLM test response:\", llm(\"How much do you know about Robert Nishihara?\"))\n",
        "\n",
        "# the retrieval model\n",
        "colbertv2_wiki17_abstracts = dspy.ColBERTv2(\n",
        "    url=\"http://20.102.90.50:2017/wiki17_abstracts\"\n",
        ")\n",
        "dspy.settings.configure(lm=llm, rm=colbertv2_wiki17_abstracts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIAYLNlcCFdO"
      },
      "source": [
        "## Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXH8qF-QBcEJ",
        "outputId": "85e8ccfe-0ad8-42fd-bd57-a501ff9dccfd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32 50\n",
            "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})\n",
            "Example({'question': 'Pehchaan: The Face of Truth stars Vinod Khanna, Rati Agnihotri and which Indian actress, producer, and former model who also produced the film?', 'answer': 'Raveena Tandon', 'gold_titles': {'Pehchaan: The Face of Truth', 'Raveena Tandon'}}) (input_keys={'question'})\n"
          ]
        }
      ],
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "\n",
        "dataset = HotPotQA(train_seed=1, train_size=32, eval_seed=2025, dev_size=50, test_size=0)\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]\n",
        "\n",
        "print(len(trainset), len(devset))\n",
        "print(trainset[0])\n",
        "print(devset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOXtqnmfCNzS"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxAaf1IABgxM",
        "outputId": "a04fa3d6-b26a-4cf9-b320-f7304b4ba4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Devset] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
            "[Devset] Answer: Frankie Goes to Hollywood\n",
            "[Devset] Relevant Wikipedia Titles: {'Twelve Inches', 'Frankie Goes to Hollywood'}\n",
            "\n",
            "[Prediction] Question: Twelve Inches is a compilation album by which 1980s British band?\n",
            "[Prediction] Predicted Answer: Spandau Ballet\n"
          ]
        }
      ],
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
        "\n",
        "\n",
        "class RAG(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = self.retrieve(question).passages\n",
        "        prediction = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
        "\n",
        "\n",
        "dev_example = devset[12]\n",
        "print(f\"[Devset] Question: {dev_example.question}\")\n",
        "print(f\"[Devset] Answer: {dev_example.answer}\")\n",
        "print(f\"[Devset] Relevant Wikipedia Titles: {dev_example.gold_titles}\")\n",
        "print()\n",
        "\n",
        "generate_answer = RAG()\n",
        "pred = generate_answer(question=dev_example.question)\n",
        "print(f\"[Prediction] Question: {dev_example.question}\")\n",
        "print(f\"[Prediction] Predicted Answer: {pred.answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytbRU9jJCSj8"
      },
      "source": [
        "## Login to LangWatch\n",
        "\n",
        "* Run LangWatch online dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF9DxTGeCU15",
        "outputId": "3d821b3d-4ef6-4eb4-8a54-1deba1f5ac2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangWatch API key is already set, if you want to login again, please call as langwatch.login(relogin=True)\n"
          ]
        }
      ],
      "source": [
        "import langwatch\n",
        "\n",
        "\n",
        "langwatch.endpoint = \"https://app.langwatch.ai\"\n",
        "langwatch.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o69S-BlkE-bV"
      },
      "source": [
        "## Start Training Session!\n",
        "\n",
        "* How does Langwatch use DsPy\n",
        "  * Langwatch's DsPy init: https://github.com/langwatch/langwatch/blob/main/python-sdk/src/langwatch/dspy.py#L151-L205\n",
        "  * DsPy Optimizer `MIPROv2`: https://github.com/stanfordnlp/dspy/blob/main/docs/docs/api/optimizers/MIPROv2.md\n",
        "    * A list of DsPy optimizers: https://github.com/stanfordnlp/dspy/tree/main/docs/docs/api/optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef67q2B-FCIP",
        "outputId": "7eddfa35-b45a-4118-eee4-15ff4cbb5877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=2 sets of demonstrations...\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing N=2 instructions...\n",
            "\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Answer questions with short factoid answers.\n",
            "\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given a context of relevant facts and a specific question, generate a clear, step-by-step reasoning process to arrive at a concise, factual answer. The reasoning should explain how the context supports the answer, which should be brief (typically 1-5 words). Ensure the response is accurate, direct, and aligned with the provided information. Use the chain-of-thought approach to justify the answer thoroughly before stating it.\n",
            "\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2025/05/09 23:04:04 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 13 - Full Evaluation of Default Program ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LangWatch] Experiment initialized, run_id: quixotic-squid-of-inspiration\n",
            "[LangWatch] Open https://app.langwatch.ai/my-garden-vZCaox/experiments/hanhan-exp1?runIds=quixotic-squid-of-inspiration to track your DSPy training session live\n",
            "\n",
            "Bootstrapping set 1/2\n",
            "Bootstrapping set 2/2\n",
            "Average Metric: 7.00 / 25 (28.0%): 100%|██████████| 25/25 [00:00<00:00, 740.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:04 INFO dspy.evaluate.evaluate: Average Metric: 7 / 25 (28.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:06 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 28.0\n",
            "\n",
            "2025/05/09 23:04:06 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 3.00 / 10 (30.0%): 100%|██████████| 10/10 [00:00<00:00, 937.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:06 INFO dspy.evaluate.evaluate: Average Metric: 3 / 10 (30.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 30.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/05/09 23:04:07 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0]\n",
            "2025/05/09 23:04:07 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0]\n",
            "2025/05/09 23:04:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:07 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:07 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 5.00 / 10 (50.0%): 100%|██████████| 10/10 [00:00<00:00, 1179.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:07 INFO dspy.evaluate.evaluate: Average Metric: 5 / 10 (50.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/05/09 23:04:08 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0]\n",
            "2025/05/09 23:04:08 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0]\n",
            "2025/05/09 23:04:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:08 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:08 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 3.00 / 10 (30.0%): 100%|██████████| 10/10 [00:00<00:00, 819.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:08 INFO dspy.evaluate.evaluate: Average Metric: 3 / 10 (30.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 30.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/05/09 23:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0]\n",
            "2025/05/09 23:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0]\n",
            "2025/05/09 23:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:09 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 5.00 / 10 (50.0%): 100%|██████████| 10/10 [00:00<00:00, 840.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:09 INFO dspy.evaluate.evaluate: Average Metric: 5 / 10 (50.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/05/09 23:04:10 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0, 50.0]\n",
            "2025/05/09 23:04:10 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0]\n",
            "2025/05/09 23:04:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:10 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 3.00 / 10 (30.0%): 100%|██████████| 10/10 [00:00<00:00, 808.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:10 INFO dspy.evaluate.evaluate: Average Metric: 3 / 10 (30.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 30.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/05/09 23:04:11 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0, 50.0, 30.0]\n",
            "2025/05/09 23:04:11 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0]\n",
            "2025/05/09 23:04:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:11 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 13 - Full Evaluation =====\n",
            "2025/05/09 23:04:11 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 50.0) from minibatch trials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 7.00 / 25 (28.0%): 100%|██████████| 25/25 [00:00<00:00, 300.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:11 INFO dspy.evaluate.evaluate: Average Metric: 7 / 25 (28.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:12 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0, 28.0]\n",
            "2025/05/09 23:04:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:12 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/05/09 23:04:12 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/05/09 23:04:12 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 6.00 / 10 (60.0%): 100%|██████████| 10/10 [00:00<00:00, 967.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:12 INFO dspy.evaluate.evaluate: Average Metric: 6 / 10 (60.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:13 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 60.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/05/09 23:04:13 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0, 50.0, 30.0, 60.0]\n",
            "2025/05/09 23:04:13 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0, 28.0]\n",
            "2025/05/09 23:04:13 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:13 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:13 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 1.00 / 10 (10.0%): 100%|██████████| 10/10 [00:00<00:00, 762.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:13 INFO dspy.evaluate.evaluate: Average Metric: 1 / 10 (10.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 10.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/05/09 23:04:14 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0, 50.0, 30.0, 60.0, 10.0]\n",
            "2025/05/09 23:04:14 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0, 28.0]\n",
            "2025/05/09 23:04:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:14 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:14 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 3.00 / 10 (30.0%): 100%|██████████| 10/10 [00:00<00:00, 1158.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:14 INFO dspy.evaluate.evaluate: Average Metric: 3 / 10 (30.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:15 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 30.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/05/09 23:04:15 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0, 50.0, 30.0, 60.0, 10.0, 30.0]\n",
            "2025/05/09 23:04:15 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0, 28.0]\n",
            "2025/05/09 23:04:15 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:15 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:15 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 2.00 / 10 (20.0%): 100%|██████████| 10/10 [00:00<00:00, 753.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:15 INFO dspy.evaluate.evaluate: Average Metric: 2 / 10 (20.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/05/09 23:04:16 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0, 50.0, 30.0, 60.0, 10.0, 30.0, 20.0]\n",
            "2025/05/09 23:04:16 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0, 28.0]\n",
            "2025/05/09 23:04:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:16 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:16 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 13 - Minibatch ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 5.00 / 10 (50.0%): 100%|██████████| 10/10 [00:00<00:00, 1450.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:16 INFO dspy.evaluate.evaluate: Average Metric: 5 / 10 (50.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:17 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 on minibatch of size 10 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/05/09 23:04:17 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [30.0, 50.0, 30.0, 50.0, 30.0, 60.0, 10.0, 30.0, 20.0, 50.0]\n",
            "2025/05/09 23:04:17 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0, 28.0]\n",
            "2025/05/09 23:04:17 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 28.0\n",
            "2025/05/09 23:04:17 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/05/09 23:04:17 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 13 - Full Evaluation =====\n",
            "2025/05/09 23:04:17 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 42.0) from minibatch trials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 8.00 / 25 (32.0%): 100%|██████████| 25/25 [00:00<00:00, 659.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:17 INFO dspy.evaluate.evaluate: Average Metric: 8 / 25 (32.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/09 23:04:18 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 32.0\n",
            "2025/05/09 23:04:18 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [28.0, 28.0, 32.0]\n",
            "2025/05/09 23:04:18 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 32.0\n",
            "2025/05/09 23:04:18 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/05/09 23:04:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/05/09 23:04:18 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 32.0!\n"
          ]
        }
      ],
      "source": [
        "from dspy.teleprompt import MIPROv2\n",
        "import dspy.evaluate\n",
        "\n",
        "\n",
        "# Define our metric validation\n",
        "def validate_context_and_answer(example, pred, trace=None):\n",
        "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
        "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
        "    return answer_EM and answer_PM\n",
        "\n",
        "# Set up a MIPROv2 optimizer, which will compile our RAG program.\n",
        "optimizer = MIPROv2(metric=validate_context_and_answer, prompt_model=llm,\n",
        "                    task_model=llm, num_candidates=2, init_temperature=0.7,\n",
        "                    auto=None)\n",
        "\n",
        "# Initialize langwatch for this run, to track the optimizer compilation\n",
        "langwatch.dspy.init(experiment=\"hanhan_exp1\", optimizer=optimizer)\n",
        "\n",
        "# Compile\n",
        "compiled_rag = optimizer.compile( RAG(),\n",
        "    trainset=trainset,\n",
        "    num_trials=10,\n",
        "    max_bootstrapped_demos=3,\n",
        "    max_labeled_demos=5,\n",
        "    minibatch_size=10,\n",
        "    requires_permission_to_run=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-7thGsMyxvP",
        "outputId": "47607f06-f402-4700-e7e9-b03b2dddd913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_answer.predict = Predict(StringSignature(context, question -> reasoning, answer\n",
              "    instructions='Given a context of relevant facts and a specific question, generate a clear, step-by-step reasoning process to arrive at a concise, factual answer. The reasoning should explain how the context supports the answer, which should be brief (typically 1-5 words). Ensure the response is accurate, direct, and aligned with the provided information. Use the chain-of-thought approach to justify the answer thoroughly before stating it.'\n",
              "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
              "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
              "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
              "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
              "))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "compiled_rag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5vA80_JJX-q"
      },
      "outputs": [],
      "source": [
        "compiled_rag.save(\"optimized_model.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "notebook_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}